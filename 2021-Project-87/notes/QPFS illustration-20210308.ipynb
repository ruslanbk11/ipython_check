{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import cvxpy\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import sklearn.metrics\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim(X):\n",
    "    return np.abs(np.corrcoef(X.T))\n",
    "\n",
    "def get_rel(X, y):\n",
    "    return np.abs(np.corrcoef(X.T, y)[:-1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(m, eps, seed):\n",
    "    np.random.seed(seed)\n",
    "    y = np.random.randn(m)\n",
    "    x1 = np.random.randn(m)\n",
    "    x2 = x1 + eps * y\n",
    "    X = np.array([x1, x2]).T\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_qpfs_from_katrutsa(b, Q):\n",
    "    a = cvxpy.Variable(Q.shape[1])\n",
    "\n",
    "    problem = cvxpy.Problem(cvxpy.Maximize(b.T @ a - cvxpy.quad_form(a, Q)), [a >= 0])\n",
    "    problem.solve(solver='ECOS')\n",
    "\n",
    "    return a.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old illustration on QPFS issues in formulation from Katrutsa_2016 paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOLUTION: [1.57577192e-02 2.01086007e-08]\n",
      "SOLUTION: [1.06763521e-07 1.14062121e-02]\n",
      "SOLUTION: [6.05254637e-03 1.22225507e-06]\n",
      "SOLUTION: [1.53284022e-08 1.74994604e-02]\n",
      "SOLUTION: [1.43859131e-06 6.10161028e-03]\n",
      "SOLUTION: [2.67123647e-08 1.50881554e-02]\n",
      "SOLUTION: [3.05848931e-04 1.16792601e-06]\n",
      "SOLUTION: [1.32540008e-02 2.88693035e-08]\n",
      "SOLUTION: [2.65498319e-07 1.87896446e-03]\n",
      "SOLUTION: [8.83238623e-03 8.84212063e-07]\n"
     ]
    }
   ],
   "source": [
    "m = 1000\n",
    "eps = 0.001\n",
    "num_attempts = 10\n",
    "\n",
    "a_list = []\n",
    "\n",
    "for seed in range(num_attempts):\n",
    "    X, y = generate_data(m, eps, seed)\n",
    "\n",
    "    b = get_rel(X, y)\n",
    "    Q = get_sim(X)\n",
    "\n",
    "    a = solve_qpfs_from_katrutsa(b, Q)\n",
    "    a_list.append(a)\n",
    "    print(\"SOLUTION:\", a)\n",
    "    \n",
    "    \n",
    "# SOLUTION: [1.57577192e-02 2.01086007e-08]\n",
    "# SOLUTION: [1.06763521e-07 1.14062121e-02]\n",
    "# SOLUTION: [6.05254637e-03 1.22225507e-06]\n",
    "# SOLUTION: [1.53284022e-08 1.74994604e-02]\n",
    "# SOLUTION: [1.43859131e-06 6.10161028e-03]\n",
    "# SOLUTION: [2.67123647e-08 1.50881554e-02]\n",
    "# SOLUTION: [3.05848931e-04 1.16792601e-06]\n",
    "# SOLUTION: [1.32540008e-02 2.88693035e-08] -> look! The better feature receives smaller, infinitisemal weights\n",
    "# SOLUTION: [2.65498319e-07 1.87896446e-03]\n",
    "# SOLUTION: [8.83238623e-03 8.84212063e-07] -> look! The better feature receives smaller, infinitisemal weights\n",
    "\n",
    "# Question 1: Why a_2 < a_1 in these two cases? -> think\n",
    "# Question 2: What can we say in general about the results of this QPFS optimization for the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Illustration of the issues for QPFS in formulation from original paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_qpfs_unconstrained(b, Q, alpha=0.5, eps=None, eps_scale=2):\n",
    "    a = cvxpy.Variable(Q.shape[1])\n",
    "    problem = cvxpy.Problem(cvxpy.Maximize(b.T @ a - cvxpy.quad_form(a, 0.5 * Q)), [a >= 0])\n",
    "    problem.solve(solver='ECOS', verbose=False, abstol=1e-10)\n",
    "    a_star = a.value.copy()\n",
    "    if eps is None:\n",
    "        eps = 1e-20 * b.shape[0]\n",
    "    while True:\n",
    "        is_improved = is_fvalue_improved(b, Q, a_star, eps)\n",
    "        #print(\"EPS / IS_IMPROVED:\", eps, is_improved)\n",
    "        if not is_improved:\n",
    "            eps = eps / eps_scale\n",
    "            break\n",
    "        eps = eps * eps_scale\n",
    "    \n",
    "    #print(\"EPS:\", eps)\n",
    "    a_star[a_star < eps] = 0\n",
    "    beta = (1 - alpha) / alpha\n",
    "    return a_star / beta, a.value / beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_fvalue_improved(b_scaled, Q_scaled, a, eps):\n",
    "    def get_fvalue(b_scaled, Q_scaled, a):\n",
    "        return np.sum(b_scaled * a) - 0.5 * np.dot(a, np.dot(Q_scaled, a))\n",
    "    idx = (a < eps)\n",
    "    if not idx.sum():\n",
    "        return True\n",
    "    if (not (~idx).sum()):\n",
    "        return False\n",
    "    cur_fvalue = get_fvalue(b_scaled, Q_scaled, a)\n",
    "    a_adj = a.copy()\n",
    "    a_adj[idx] = 0\n",
    "    a_adj = a_adj / a_adj.sum() * a.sum()\n",
    "    new_fvalue = get_fvalue(b_scaled, Q_scaled, a_adj)\n",
    "    #print(\"DIFF:\", new_fvalue - cur_fvalue)\n",
    "    return (new_fvalue >= cur_fvalue)\n",
    "\n",
    "def solve_qpfs_original(b, Q, alpha=0.5, debug=False, robust=False, eps=None, eps_scale=2):\n",
    "    a = cvxpy.Variable(Q.shape[1])\n",
    "    \n",
    "    b_scaled = b * alpha\n",
    "    Q_scaled = Q * (1 - alpha)\n",
    "    \n",
    "    if alpha == 1:\n",
    "        if not robust:\n",
    "            problem = cvxpy.Problem(cvxpy.Maximize(b_scaled.T @ a), [a >= 0, cvxpy.sum(a) == 1])\n",
    "        else:\n",
    "            problem = cvxpy.Problem(cvxpy.Maximize(b_scaled.T @ a), [a >= 0, cvxpy.sum(a) <= 1])\n",
    " \n",
    "    else:\n",
    "        if not robust:\n",
    "            problem = cvxpy.Problem(cvxpy.Maximize(b_scaled.T @ a - cvxpy.quad_form(a, 0.5 * Q_scaled)), [a >= 0, cvxpy.sum(a) == 1])\n",
    "        else:\n",
    "            problem = cvxpy.Problem(cvxpy.Maximize(b_scaled.T @ a - cvxpy.quad_form(a, 0.5 * Q_scaled)), [a >= 0, cvxpy.sum(a) <= 1])\n",
    "\n",
    "    problem.solve(solver='ECOS', verbose=False, abstol=1e-10)\n",
    "\n",
    "    a_star = a.value.copy()\n",
    "    #print(a.value)\n",
    "    if eps is None:\n",
    "        eps = 1e-20 * b.shape[0]\n",
    "    while True:\n",
    "        is_improved = is_fvalue_improved(b_scaled, Q_scaled, a_star, eps)\n",
    "        #print(\"EPS / IS_IMPROVED:\", eps, is_improved)\n",
    "        if not is_improved:\n",
    "            eps = eps / eps_scale\n",
    "            break\n",
    "        eps = eps * eps_scale\n",
    "    \n",
    "    #print(\"EPS:\", eps)\n",
    "    a_star[a_star < eps] = 0\n",
    "    a_star = a_star / (1e-20 + a_star.sum())\n",
    "    return a_star, a.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function generates a dataset with several noise features (irrelevant) \n",
    "# and target variable being the difference of another two features after proper scaling\n",
    "\n",
    "def generate_data_with_diff_and_noise(m, eps, num_noise, seed):\n",
    "    np.random.seed(seed)\n",
    "    y = np.random.randn(m)\n",
    "    x1 = np.random.randn(m)\n",
    "    x2 = x1 + eps * y\n",
    "    X = np.array([x1, x2]).T\n",
    "    X_noise = np.random.randn(m, num_noise)\n",
    "    return np.concatenate((X, X_noise), axis=1), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_solution(a):\n",
    "    num_active_noise = (a[2:] > 0).sum()\n",
    "    is_active_first = int(a[0] > 0)\n",
    "    is_active_second = int(a[1] > 0)\n",
    "    num_noises_greater_than_second = (a[2:] > a[1]).sum()\n",
    "    return is_active_first, is_active_second, num_active_noise, num_noises_greater_than_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.8 s, sys: 112 ms, total: 21.9 s\n",
      "Wall time: 29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m = 10000\n",
    "eps = 0.01\n",
    "num_noise = 10\n",
    "robust = False # when set to True we solve for ||a||_1 <= beta\n",
    "# Setting it as an equality constraint, actually starts to act in a weird way for beta = alpha / (1 - alpha) > ||b||_1\n",
    "# If ||a||_1 is forced to be big (e.g. alpha=1), the maximum of b^T a is achieved for degenerate solution \n",
    "# putting everything in a single feature with biggest similarity.\n",
    "# This is actually the reversal of what is happening when the inequality constraint is still tight.\n",
    "\n",
    "solution_info_df = pd.DataFrame(dtype=float, columns=[\"alpha\", \"seed\", \"is_active1\", \"is_active2\", \"num_active_noises\", \"num_better_noises\"])\n",
    "idx = 0\n",
    "\n",
    "alpha_list = [0] + list(np.logspace(-6, -2, 5)) + list(np.linspace(0.015, 0.985, 98)) + \\\n",
    "list(1. - np.logspace(-6, -2, 9)[::-1]) + [1]\n",
    "\n",
    "seed = 11\n",
    "X, y = generate_data_with_diff_and_noise(m, eps, num_noise, seed)\n",
    "\n",
    "for seed in range(10):\n",
    "    b = get_rel(X, y)\n",
    "    Q = get_sim(X)\n",
    "\n",
    "    for alpha in alpha_list:\n",
    "        try:\n",
    "            cur_a, _ = solve_qpfs_original(b, Q, alpha, robust=robust)\n",
    "            solution_info_df.loc[idx] = [alpha, seed] + list(analyze_solution(cur_a))\n",
    "        except:\n",
    "            print(f\"ISSUE WITH ALPHA={alpha}, seed={seed}\")\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_solution_df = solution_info_df.groupby(\"alpha\").mean().loc[:, [\"is_active1\", \"is_active2\",\\\n",
    "                                                                   \"num_active_noises\", \"num_better_noises\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_active1</th>\n",
       "      <th>is_active2</th>\n",
       "      <th>num_active_noises</th>\n",
       "      <th>num_better_noises</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000010</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.015000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.025000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.035000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.045000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.055000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.065000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.075000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.085000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.095000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.105000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.115000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.125000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.135000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.145000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.155000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.165000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.175000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.185000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.195000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.205000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.215000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.225000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.235000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.245000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.795000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.805000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.815000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.825000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.835000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.845000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.855000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.865000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.875000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.885000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.895000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.905000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.915000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.925000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.935000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.945000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.955000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.965000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.975000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.985000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.990000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.996838</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999684</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999900</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999968</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999990</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          is_active1  is_active2  num_active_noises  num_better_noises\n",
       "alpha                                                                 \n",
       "0.000000         0.0         1.0               10.0                6.0\n",
       "0.000001         0.0         1.0               10.0                6.0\n",
       "0.000010         0.0         1.0               10.0                6.0\n",
       "0.000100         0.0         1.0               10.0                6.0\n",
       "0.001000         0.0         1.0               10.0                6.0\n",
       "0.010000         0.0         1.0               10.0                6.0\n",
       "0.015000         0.0         1.0               10.0                6.0\n",
       "0.025000         0.0         1.0               10.0                5.0\n",
       "0.035000         0.0         1.0               10.0                5.0\n",
       "0.045000         0.0         1.0               10.0                5.0\n",
       "0.055000         0.0         1.0               10.0                5.0\n",
       "0.065000         0.0         1.0               10.0                5.0\n",
       "0.075000         0.0         1.0               10.0                5.0\n",
       "0.085000         0.0         1.0               10.0                5.0\n",
       "0.095000         0.0         1.0               10.0                5.0\n",
       "0.105000         0.0         1.0               10.0                5.0\n",
       "0.115000         0.0         1.0               10.0                5.0\n",
       "0.125000         0.0         1.0               10.0                5.0\n",
       "0.135000         0.0         1.0               10.0                4.0\n",
       "0.145000         0.0         1.0               10.0                4.0\n",
       "0.155000         0.0         1.0               10.0                4.0\n",
       "0.165000         0.0         1.0               10.0                4.0\n",
       "0.175000         0.0         1.0               10.0                4.0\n",
       "0.185000         0.0         1.0               10.0                3.0\n",
       "0.195000         0.0         1.0               10.0                3.0\n",
       "0.205000         0.0         1.0               10.0                3.0\n",
       "0.215000         0.0         1.0               10.0                3.0\n",
       "0.225000         0.0         1.0               10.0                3.0\n",
       "0.235000         0.0         1.0               10.0                3.0\n",
       "0.245000         0.0         1.0               10.0                3.0\n",
       "...              ...         ...                ...                ...\n",
       "0.795000         0.0         1.0               10.0                2.0\n",
       "0.805000         0.0         1.0               10.0                2.0\n",
       "0.815000         0.0         1.0               10.0                2.0\n",
       "0.825000         0.0         1.0               10.0                2.0\n",
       "0.835000         0.0         1.0               10.0                2.0\n",
       "0.845000         0.0         1.0               10.0                2.0\n",
       "0.855000         0.0         1.0               10.0                2.0\n",
       "0.865000         0.0         1.0               10.0                2.0\n",
       "0.875000         0.0         1.0               10.0                2.0\n",
       "0.885000         0.0         1.0               10.0                2.0\n",
       "0.895000         0.0         1.0               10.0                2.0\n",
       "0.905000         0.0         1.0                8.0                2.0\n",
       "0.915000         0.0         1.0                8.0                2.0\n",
       "0.925000         0.0         1.0                7.0                2.0\n",
       "0.935000         0.0         1.0                7.0                2.0\n",
       "0.945000         0.0         1.0                7.0                2.0\n",
       "0.955000         0.0         1.0                6.0                2.0\n",
       "0.965000         0.0         1.0                5.0                2.0\n",
       "0.975000         0.0         1.0                5.0                2.0\n",
       "0.985000         0.0         1.0                2.0                2.0\n",
       "0.990000         0.0         1.0                2.0                2.0\n",
       "0.996838         0.0         0.0                2.0                2.0\n",
       "0.999000         0.0         0.0                1.0                1.0\n",
       "0.999684         0.0         0.0                1.0                1.0\n",
       "0.999900         0.0         0.0                1.0                1.0\n",
       "0.999968         0.0         0.0                1.0                1.0\n",
       "0.999990         0.0         0.0                1.0                1.0\n",
       "0.999997         0.0         0.0                1.0                1.0\n",
       "0.999999         0.0         0.0                1.0                1.0\n",
       "1.000000         0.0         0.0                1.0                1.0\n",
       "\n",
       "[114 rows x 4 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_solution_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAT5klEQVR4nO3de3BcZ3nH8d8jrSJZq2siR3ES4hUkAVI3LVjcmVQiSRNSSqDDgBlC006mHug0TVsuBfJHKQwDw0xhwgwzxVMYkpIiWpcBw9ALEAkDTVzsJDWOzdWXxLUTJRBfZMu6+ekfu3IdWZZW57b77vl+ZjTWXs6e57GUX47fc877mrsLABCeploXAACIhgAHgEAR4AAQKAIcAAJFgANAoApZ7qyvr89LpVKkbU+cOKFisZhsQXWOnvOBnhtf3H537NjxjLuvXvh8pgFeKpW0ffv2SNuOjY1paGgo2YLqHD3nAz03vrj9mtmBxZ5nCAUAAkWAA0CgCHAACBQBDgCBIsABIFDLBriZfcHMxs1s11nPXWhm3zazn1f+7E23TADAQtUcgX9R0s0LnvuApO+6+1WSvlt5DADI0LLXgbv7VjMrLXj6VklDle/vlTQm6a8TrOs5vvHLb2jrka3a9ciu5d/cQA4cOUDPOUDP6eu8oFO3vfg2NTc1Z7bPLES9kaff3Q9LkrsfNrOLz/dGM9soaaMk9ff3a2xsbMU7u3/8fu2e3C3tjFhtyOg5H+g5Na7ymgd+0FVqLWWz0wUmJiYiZd+y3H3ZL0klSbvOenxkwevPVvM569ev96hGR0cjbxsqes4Hek7XzvGdvu6L63zs8bHM9rlQ3H4lbfdFMjXqVShPmdkaSar8OR77/yQAkIKeth5J0pGpIzWuJHlRA3yLpNsr398u6evJlAMAyeptLV8kl8sAN7MvS3pQ0gvN7KCZ3SHpE5JuNLOfS7qx8hgA6k6xpahCU0HPnnq21qUkrpqrUN5+npeuT7gWAEicmamntSefR+AAEDoCHAAC1dvW25BDKAQ4gIbHETgABIoAB4BA9bT26OjUUZ3207UuJVEEOICG19vWqzmf0/Hp47UuJVEEOICG19Navhvz6NTRGleSLAIcQMObD/BnpxrrShQCHEDD622r3E5/qrFOZBLgABped2u3JI7AASA48xNaMQYOAIFp1AmtCHAADc/M1Nva23A38xDgAHKhu7WbI3AACFFvG0fgABCkRpwPhQAHkAsEOAAEqhEntCLAAeRCI05oRYADyIX5+VAaaRiFAAeQC2cmtGqgSwkJcAC5MD+hVSPdTk+AA8iFRpxSlgAHkAuNOKUsAQ4gF9oL7So0FTiJCQChacQJrQhwALnR09bDVSgAEKJGu52eAAeQGwQ4AASKMXAACFRPW/kIvFEmtIoV4Gb2l2b2mJntMrMvm1lbUoUBQNJ6Wnt02k83zIRWkQPczC6T9OeSBt19naRmSRuSKgwAktZoE1oVEth+lZnNSGqXdCh+SQCQjgvbLpQkvelrb5KZqa25Tfe+/l5d1XtVjSuLxtw9+sZmd0n6mKRJSf/p7u9Y5D0bJW2UpP7+/vUjIyOR9jUxMaGOjo7ItYaInvOBnrMzfXpao8dHNXV6SjM+o7HjY3rbhW/Taztfm+p+4/Y7PDy8w90Hz3nB3SN9SeqV9ICk1ZJaJH1N0m1LbbN+/XqPanR0NPK2oaLnfKDn2pg7Pecv+9LL/BPbPpH6vuL2K2m7L5KpcU5i3iBpn7s/7e4zkr4q6dUxPg8AMtNkTVrbtVb7ju2rdSmRxQnwxyW90szazcwkXS9pTzJlAUD6BroGtP/o/lqXEVnkAHf3bZI2S3pY0o8rn7UpoboAIHWl7pIOTRzS1NxUrUuJJNZ14O7+N+7+Indf5+7vdPcw/xYA5FKpqySX68CxA7UuJRLuxASQWwPdA5IU7DAKAQ4gt9Z2rZUk7Tsa5olMAhxAbrW3tOuS4iXaf2x/rUuJhAAHkGulrhJDKAAQooHuAe07tm/+BsWgEOAAcq3UVdKJmRN6ZvKZWpeyYgQ4gFybvxIlxBOZBDiAXDtzKWGAJzIJcAC5dnH7xVpVWMUROACEpsmaVOoqBTmpFQEOIPdK3WFeSkiAA8i9ga4BHZo4pFOzp2pdyorEXVINAIJX6i5PavW9g9/T5R2XP+e1QlNBV/Zcqeam5hpVd34EOIDcu7r3aknSe7/33kVf/8irP6I3X/XmLEuqCgEOIPde0PMC3ff6+3Rs6tg5r71/6/v1k1//pAZVLY8ABwBJL7n4JYs+P9A9ULfXiHMSEwCWUOou1e014gQ4ACyh1FXS4ROHNTk7WetSzkGAA8AS5m+1r8dl1whwAFhCqaskqT6XXSPAAWAJa7vWymR1OQ5OgAPAEtoKbbq049K6nCuFAAeAZdTrXCkEOAAsY6CrfC34aT9d61KegwAHgGWUukqanJ3U+MnxWpfyHAQ4ACyjXpddI8ABYBml7pKk+lt2jQAHgGWsXrVaxZYiR+AAEBozU6mr/q5EIcABoAql7vpbNzNWgJtZj5ltNrOfmNkeM3tVUoUBQD0Z6BrQkyee1MmZk7Uu5Yy4R+D3SPp3d3+RpN+StCd+SQBQf+ZPZNbTpFaRA9zMuiRdJ+nzkuTu0+5+JKnCAKCezF9KWE9Xopi7R9vQ7LclbZK0W+Wj7x2S7nL3Ewvet1HSRknq7+9fPzIyEml/ExMT6ujoiLRtqOg5H+g5DDM+o/c8/h7d3H2zbum5ZUXbxu13eHh4h7sPnvOCu0f6kjQoaVbSKyqP75H00aW2Wb9+vUc1OjoaedtQ0XM+0HM4btp8k79v7H0r3i5uv5K2+yKZGmcM/KCkg+6+rfJ4s6SXxvg8AKhrpe5SXQ2hRA5wd39S0hNm9sLKU9erPJwCAA2p3ia1irsq/Z2S7jezCyTtlfTH8UsCgPo00D1wZlKrS4qX1LqceAHu7o+qPBYOAA1vfnm1vUf31kWAcycmAFTpzKWEdXJLPQEOAFXqW9VXV5NaEeAAUKUzk1rVyZUoBDgArMBA9wABDgAhKnWV6mZSKwIcAFZg/kRmPUxqRYADwArMz0pYDycyCXAAWIErOq+QyepiHJwAB4AVaCu06dKOS+viWnACHABWqF6WVyPAAWCFBroGdODYgZpPakWAA8AKzU9q9dSJp2paBwEOACs0P6lVrYdR4k4nCwC5M38t+D0P36PNP9ssk+n237hd166+NtM6CHAAWKG+VX264YobtP/Yfu07uk97j+5V36o+AhwA6p2Z6dPDnz7z+MbNN+rEzIkltkgHY+AAEFOxUNTJ2eznRiHAASCmYkuRI3AACFF7S7smZiYy3y8BDgAxFVuKNZlelgAHgJgYQgGAQBHgABCo+SEUd890vwQ4AMRUbClq1mc1fXo60/0S4AAQU3uhXZIyH0YhwAEgpmJLURIBDgDBIcABIFAEOAAEigAHgEDNB3jWd2MS4AAQU7BH4GbWbGaPmNk3kygIAELT3hLuZYR3SdqTwOcAQJDOXAc+G1CAm9nlkn5P0j8kUw4AhKfQVFBbc5tOTGcb4Bbn3n0z2yzp45I6Jb3X3d+wyHs2StooSf39/etHRkYi7WtiYkIdHR2Raw0RPecDPTeGDz3xIV3bfq02XLThnNfi9js8PLzD3QcXPh95TUwze4OkcXffYWZD53ufu2+StEmSBgcHfWjovG9d0tjYmKJuGyp6zgd6bgy9X+1VV1+Xhq4bOue1tPqNM4TyGklvNLP9kkYkvc7MvpRIVQAQmFos6hA5wN39g+5+ubuXJG2Q9IC735ZYZQAQkPaW9iCvQgGA3KvFog6JBLi7jy12AhMA8qJYKOrkbCBDKACA/9fe0q6J6WxXpifAASABHS0dHIEDQIiKLUVNzk5q7vRcZvskwAEgAfPzoWR5FE6AA0ACajEjIQEOAAmoxZzgBDgAJIAjcAAI1PyUshMz2V1KSIADQAI6LijPNsgQCgAEplioDKFkuKgDAQ4ACajFsmoEOAAkgJOYABCo1uZWNVszY+AAEBozy3xOcAIcABJSbClyGSEAhKijpYMhFAAIEUMoABCoYqHIdeAAEKKsV6YnwAEgIQyhAECgsl6ZngAHgITMB7i7Z7I/AhwAElJsKWrO5zQ1N5XJ/ghwAEhI1vOhEOAAkJCsl1UjwAEgIVnPCU6AA0BCsp4TnAAHgIQwBg4AgSLAASBQwQS4mT3PzEbNbI+ZPWZmdyVZGACEJusAL8TYdlbSe9z9YTPrlLTDzL7t7rsTqg0AgtJeKJ/EzOoywsgB7u6HJR2ufH/czPZIukwSAQ4gl5qbmrWqsEo7n9mpLb/cIknqbOmUUrqz3pK4Z9/MSpK2Slrn7scWvLZR0kZJ6u/vXz8yMhJpHxMTE+ro6IhXaGDoOR/oubF87NDH9OTMk8957q7uu3Rlz5WRP3N4eHiHuw8ufD7OEIokycw6JP2rpL9YGN6S5O6bJG2SpMHBQR8aGoq0n7GxMUXdNlT0nA/03FhePvNy/erUryRJj4w/ort/cLea2ppS6TdWgJtZi8rhfb+7fzWZkgAgXO0t7Wdu6Bk/OS5JmvbpVPYV5yoUk/R5SXvc/VPJlQQAjaG1uVWSNOuzqXx+nOvAXyPpnZJeZ2aPVr5uSaguAAjefIDP+Ewqnx/nKpQfSLIEawGAhpJ2gHMnJgCkhAAHgEAR4AAQqNYCAQ4AQeIIHAAC1WRNamlqIcABIEStza11eR04AGAZrc2tHIEDQIgIcAAIVGuBAAeAIHEEDgCBIsABIFAEOAAEKs0Aj70iTya2fU5X//Q70rF8rRlx9eHD9JwD9NygOi6Whj6k1uZWPTH9hJ4++bRWt69OdBdhBPj/7tBFv/qRdLy11pVk6qLpKXrOAXpuQLOT0qmj0m++VYOXDGrbwW2anJ1MfDdhBPgfbNKDDbyG3vnQcz7QcwPat1W69/el44f0jhe/Q5c9dZmu6Loi8d0wBg4ASeu8tPznscOp7oYAB4Ckda0p/3mcAAeAsFxQlFq7CXAACFLXGunYoVR3QYADQBo613AEDgBB6rqUk5gAEKTONdLEU9LpudR2QYADQBq61kg+J02Mp7YLAhwA0jB/Lfjx9E5kEuAAkIb5a8FTHAcnwAEgDWeOwAlwAAhLcbXUVEj1WnACHADS0NQkdVzCETgABCnluzEJcABIS8p3Y8YKcDO72cx+ama/MLMPJFUUADSElO/GjBzgZtYs6bOSXi/pGklvN7NrkioMAILXuUaaPq7m2ZOpfLy5e7QNzV4l6cPuflPl8Qclyd0/fr5tBgcHffv27Sve199+4zH91+7H1dPTE6nWUB05coSec4CeG9drJx/QnUc+qZO2Su13PihdOBDpc8xsh7sPLnw+zpJql0l64qzHByW9YpEdb5S0UZL6+/s1Nja24h0dPDilubk5HTlyJFqlgaLnfKDnxvV9f4Fe1HydeppOaeZHD2u69UCinx8nwG2R5845nHf3TZI2SeUj8Cjr4A0NSWONvobeIug5H+i50W1Ird84JzEPSnreWY8vl5Tu7OUAgDPiBPiPJF1lZgNmdoGkDZK2JFMWAGA5kYdQ3H3WzP5M0n9Iapb0BXd/LLHKAABLijMGLnf/lqRvJVQLAGAFuBMTAAJFgANAoAhwAAgUAQ4AgYp8K32knZk9LSnqrUh9kp5JsJwQ0HM+0HPji9vvWndfvfDJTAM8DjPbvthcAI2MnvOBnhtfWv0yhAIAgSLAASBQIQX4ploXUAP0nA/03PhS6TeYMXAAwHOFdAQOADgLAQ4Agaq7AF9uoWQzazWzr1Re32ZmpeyrTFYVPf+Vme02s51m9l0zW1uLOpNU7YLYZvYWM3MzC/qSs2r6NbO3Vn7Oj5nZP2VdY9Kq+L2+wsxGzeyRyu/2LbWoM0lm9gUzGzezXed53czsM5W/k51m9tJYO3T3uvlSeVraX0p6vqQLJP2PpGsWvOdPJf195fsNkr5S67oz6HlYUnvl+3fnoefK+zolbZX0kKTBWted8s/4KkmPSOqtPL641nVn0PMmSe+ufH+NpP21rjuBvq+T9FJJu87z+i2S/k3lFc1eKWlbnP3V2xH4yyX9wt33uvu0pBFJty54z62S7q18v1nS9Wa22PJuoVi2Z3cfdff5Za0fUnn1o5BV83OWpI9K+qSkU1kWl4Jq+v0TSZ9192clyd3HM64xadX07JK6Kt93qwFW9HL3rZJ+vcRbbpV0n5c9JKnHzNZE3V+9BfhiCyVfdr73uPuspKOSLsqkunRU0/PZ7lD5/+AhW7ZnM3uJpOe5+zezLCwl1fyMr5Z0tZn90MweMrObM6suHdX0/GFJt5nZQZXXFbgzm9JqaqX/vS8p1oIOKahmoeSqFlMOSNX9mNltkgYl/U6qFaVvyZ7NrEnSpyX9UVYFpayan3FB5WGUIZX/hfV9M1vn7qEu3V5Nz2+X9EV3/zsze5Wkf6z0fDr98mom0fyqtyPwahZKPvMeMyuo/E+vpf7JUu+qWhzazG6QdLekN7r7VEa1pWW5njslrZM0Zmb7VR4r3BLwicxqf6+/7u4z7r5P0k9VDvRQVdPzHZL+WZLc/UFJbSpP+tTIEl0Mvt4CvJqFkrdIur3y/VskPeCVswOBWrbnynDC51QO79DHRqVlenb3o+7e5+4ldy+pPO7/RnffXptyY6vm9/prKp+slpn1qTyksjfTKpNVTc+PS7pekszsxSoH+NOZVpm9LZL+sHI1yislHXX3w5E/rdZnbc9zlvZnKp/Bvrvy3EdU/g9YKv+Q/0XSLyT9t6Tn17rmDHr+jqSnJD1a+dpS65rT7nnBe8cU8FUoVf6MTdKnJO2W9GNJG2pdcwY9XyPphypfofKopN+tdc0J9PxlSYclzah8tH2HpHdJetdZP+fPVv5Ofhz395pb6QEgUPU2hAIAqBIBDgCBIsABIFAEOAAEigAHgEAR4AAQKAIcAAL1f3aqf8gpbBPUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(alpha_list, avg_solution_df[\"is_active1\"]) # first feature is never active\n",
    "plot(alpha_list, avg_solution_df[\"is_active2\"]) \n",
    "# second feature is active until alpha=0.99, \n",
    "# when 2 out of 10 noises remain active and have higher weight than 2nd feature\n",
    "plot(alpha_list, avg_solution_df[\"num_active_noises\"]) # all 10 noises remain active until alpha=0.895 \n",
    "# (2 have higher a* than the second feature that is in reality relevant to y)\n",
    "# In the end remain just one feature, and the feature is the noise one!\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.01603855, 0.        , 0.01996452, 0.00850171,\n",
       "        0.01294355, 0.        , 0.01236458, 0.01138127, 0.00248603,\n",
       "        0.00706283, 0.01850955]),\n",
       " array([4.10874765e-12, 1.60385463e-02, 3.96982478e-10, 1.99645185e-02,\n",
       "        8.50171267e-03, 1.29435519e-02, 6.18490556e-11, 1.23645795e-02,\n",
       "        1.13812674e-02, 2.48603341e-03, 7.06282540e-03, 1.85095527e-02]))"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_qpfs_unconstrained(b, Q) # even unconstrained solution has 0 weight on first feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multicollinearity illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "n = 10\n",
    "m = 1000\n",
    "\n",
    "eps = 0.001 # illustrates strong multicollinearity. Yet when keeping all features we do better in testing sample.\n",
    "# The higher condition number did not result in deterioration in performance.\n",
    "eps = 1 # illustrates potential benefits from keeping more features (there is less multicollinearity here though)\n",
    "\n",
    "y = np.random.randn(m)\n",
    "X = eps * np.random.randn(m, n) + y[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_test = 10000\n",
    "y_test = np.random.randn(m_test)\n",
    "X_test = eps * np.random.randn(m_test, n) + y_test[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regr = sm.OLS(y, X)\n",
    "linear_regr = linear_regr.fit()\n",
    "\n",
    "linear_regr_one = sm.OLS(y, X[:, :1])\n",
    "linear_regr_one = linear_regr_one.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2, %: [91.1018374, 49.6988733]\n",
      "R2 gap to 100%, %: [8.8981626, 50.3011267]\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted = linear_regr.predict(X_test)\n",
    "y_test_predicted_one = linear_regr_one.predict(X_test[:, :1])\n",
    "\n",
    "r2_all = sklearn.metrics.r2_score(y_test, y_test_predicted)\n",
    "r2_one = sklearn.metrics.r2_score(y_test, y_test_predicted_one)\n",
    "\n",
    "print(\"R2, %:\", [np.round(item, 7) for item in [100 * r2_all, 100 * r2_one]])\n",
    "print(\"R2 gap to 100%, %:\", [np.round(100 - item, 7) for item in [100 * r2_all, 100 * r2_one]])\n",
    "\n",
    "#99.90153840975476 98.99507045582031\n",
    "#0.09846159024523615 1.0049295441796886"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.906\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.905\n",
      "Method:                 Least Squares   F-statistic:                              953.4\n",
      "Date:                Wed, 31 Mar 2021   Prob (F-statistic):                        0.00\n",
      "Time:                        16:01:48   Log-Likelihood:                         -238.64\n",
      "No. Observations:                1000   AIC:                                      497.3\n",
      "Df Residuals:                     990   BIC:                                      546.4\n",
      "Df Model:                          10                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0894      0.010      9.257      0.000       0.070       0.108\n",
      "x2             0.0856      0.010      8.854      0.000       0.067       0.105\n",
      "x3             0.0970      0.009     10.281      0.000       0.078       0.116\n",
      "x4             0.0994      0.010     10.437      0.000       0.081       0.118\n",
      "x5             0.0857      0.009      9.127      0.000       0.067       0.104\n",
      "x6             0.0893      0.009      9.477      0.000       0.071       0.108\n",
      "x7             0.1065      0.009     11.835      0.000       0.089       0.124\n",
      "x8             0.0842      0.009      9.134      0.000       0.066       0.102\n",
      "x9             0.0848      0.009      9.173      0.000       0.067       0.103\n",
      "x10            0.0980      0.009     10.391      0.000       0.080       0.117\n",
      "==============================================================================\n",
      "Omnibus:                        0.170   Durbin-Watson:                   1.852\n",
      "Prob(Omnibus):                  0.918   Jarque-Bera (JB):                0.237\n",
      "Skew:                           0.022   Prob(JB):                        0.888\n",
      "Kurtosis:                       2.939   Cond. No.                         3.59\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(linear_regr.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, multicollinearity is strong (condition number is 3.47e3)\n",
    "Yet, there is no issue in estimation, and we do get better R2 with 10 features vs 1.\n",
    "We are already close to 100% R2, so the gain does not appear that big.\n",
    "Yet, the same is pronounced for higher eps, which would mean lower R2 for a single feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
