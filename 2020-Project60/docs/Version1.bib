% Encoding: UTF-8

@InProceedings{conf/cvpr/VeniatD18,
  author    = {Tom Veniat and Ludovic Denoyer},
  title     = {Learning Time/Memory-Efficient Deep Architectures With Budgeted Super Networks},
  booktitle = {CVPR},
  year      = {2018},
  pages     = {3492--3500},
  publisher = {IEEE Computer Society},
  bibdate   = {2019-02-06},
  bibsource = {DBLP, http://dblp.uni-trier.de/https://doi.org/10.1109/CVPR.2018.00368; DBLP, http://dblp.uni-trier.de/db/conf/cvpr/cvpr2018.html#VeniatD18},
  crossref  = {conf/cvpr/2018},
  url       = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=8576498},
}

@Article{journals/corr/SaxenaV16,
  author    = {Shreyas Saxena and Jakob Verbeek},
  title     = {Convolutional Neural Fabrics},
  journal   = {CoRR},
  year      = {2016},
  volume    = {abs/1606.02492},
  bibdate   = {2018-08-13},
  bibsource = {DBLP, http://dblp.uni-trier.de/db/journals/corr/corr1606.html#SaxenaV16},
  url       = {http://arxiv.org/abs/1606.02492},
}

@InProceedings{conf/nips/Graves11,
  author    = {Alex Graves},
  title     = {Practical Variational Inference for Neural Networks},
  booktitle = {Advances in Neural Information Processing Systems 24: 25th Annual Conference on Neural Information Processing Systems 2011. Proceedings of a meeting held 12-14 December 2011, Granada, Spain},
  year      = {2011},
  editor    = {John Shawe-Taylor and Richard S. Zemel and Peter L. Bartlett and Fernando C. N. Pereira and Kilian Q. Weinberger},
  pages     = {2348--2356},
  bibdate   = {2014-12-10},
  bibsource = {DBLP, http://dblp.uni-trier.de/db/conf/nips/nips2011.html#Graves11},
  url       = {http://papers.nips.cc/book/advances-in-neural-information-processing-systems-24-2011},
}

@Article{journals/corr/HaDL16,
  author    = {David Ha and Andrew M. Dai and Quoc V. Le},
  title     = {HyperNetworks},
  journal   = {CoRR},
  year      = {2016},
  volume    = {abs/1609.09106},
  bibdate   = {2018-08-13},
  bibsource = {DBLP, http://dblp.uni-trier.de/db/journals/corr/corr1609.html#HaDL16},
  url       = {http://arxiv.org/abs/1609.09106},
}

@Article{journals/corr/abs-1812-09926,
  author    = {Sirui Xie and Hehui Zheng and Chunxiao Liu and Liang Lin},
  title     = {SNAS: Stochastic Neural Architecture Search},
  journal   = {CoRR},
  year      = {2018},
  volume    = {abs/1812.09926},
  bibdate   = {2019-01-02},
  bibsource = {DBLP, http://dblp.uni-trier.de/db/journals/corr/corr1812.html#abs-1812-09926},
  url       = {http://arxiv.org/abs/1812.09926},
}

@Article{journals/corr/abs-1812-03443,
  author    = {Bichen Wu and Xiaoliang Dai and Peizhao Zhang and Yanghan Wang and Fei Sun and Yiming Wu and Yuandong Tian and Peter Vajda and Yangqing Jia and Kurt Keutzer},
  title     = {FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search},
  journal   = {CoRR},
  year      = {2018},
  volume    = {abs/1812.03443},
  bibdate   = {2019-01-01},
  bibsource = {DBLP, http://dblp.uni-trier.de/db/journals/corr/corr1812.html#abs-1812-03443},
  url       = {http://arxiv.org/abs/1812.03443},
}

@article{lecun-mnisthandwrittendigit-2010,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}

@article{cif,
title= {CIFAR-10 (Canadian Institute for Advanced Research)},
journal= {},
author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
year= {},
url= {http://www.cs.toronto.edu/~kriz/cifar.html},
abstract= {The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. 

The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. },
keywords= {Dataset},
terms= {}
}

@Comment{jabref-meta: databaseType:bibtex;}
